{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Convolution is the concent of a sliding window function which moves a amount defined by the stride.\n",
    "\n",
    "Now you know what convolutions are. But what about CNNs? CNNs are basically just several layers of convolutions with nonlinear activation functions like ReLU or tanh applied to the results. In a traditional feedforward neural network we connect each input neuron to each output neuron in the next layer. That’s also called a fully connected layer, or affine layer. In CNNs we don’t do that. Instead, we use convolutions over the input layer to compute the output. This results in local connections, where each region of the input is connected to a neuron in the output. \n",
    "\n",
    "Pooling refers to reducing the output of all the layers 1 level of the network which is passed as 1 input again to the next iteration layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "See illustration at http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "\n",
    "Also, Convolutional neural networks (CNN) are designed to recognize images. It has convolutions inside, which see the edges of an object recognized on the image. Recurrent neural networks (RNN) are designed to recognize sequences, for example, a speech signal or a text. The recurrent network has cycles inside that implies the presence of short memory in the net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setting up tensforflow parameters\n",
    "learning_rate =  0.001 \n",
    "training_epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "n_inputs = 784 #MNIST data 28*28=784 for each image\n",
    "n_classes = 10 #Output can be 1 of the 10 numbers\n",
    "dropout_percentage = 0.75 #Dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#TF graph inputs\n",
    "\n",
    "#mnist images are of shape 28*28 = 784\n",
    "#We do not know the number of images/ they will be different for train and test thus None, 784\n",
    "x = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "#y, i.e. the result can be any number from 0 to 9 in onehot encoded format\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) \n",
    "\n",
    "#Keep probaility of the possible drop outs\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Defining weights and bias\n",
    "W = {## 5x5 convolution, 1 input and 32 outputs\n",
    "     \"w1\": tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "     ## 5x5 convolution, 32 inputs, 64 outputs\n",
    "     \"w2\": tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "     ## Fully connected, 7*7*64 inputs, 1024 outputs\n",
    "     \"w_full\": tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "     ## 1024 inputs, 10 output classes\n",
    "     \"w_\": tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "    \n",
    "    }\n",
    "\n",
    "b = {\"b1\": tf.Variable(tf.random_normal([32])),\n",
    "     \"b2\": tf.Variable(tf.random_normal([64])),\n",
    "     \"b_full\": tf.Variable(tf.random_normal([1024])),\n",
    "     \"b_\": tf.Variable(tf.random_normal([n_classes]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k = 2):\n",
    "    #MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], \n",
    "                          strides = [1, k, k, 1], \n",
    "                          padding= \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Model construction\n",
    "def conv_net(x, ws, bs, dropouts):\n",
    "    #Reshape input\n",
    "    xs = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "    stride = 1\n",
    "    \n",
    "    #convolution layer\n",
    "    x_ = tf.nn.conv2d(xs, ws[\"w1\"], strides = [1, stride, stride, 1], padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x_, bs[\"b1\"])\n",
    "    conv1 = tf.nn.relu(x)\n",
    "    #max pooling (down-sampling)\n",
    "    output_layer_1 = maxpool2d(conv1)\n",
    "    \n",
    "    #convolution layer\n",
    "    output_layer_2 = tf.nn.conv2d(output_layer_1, ws[\"w2\"], strides = [1, stride, stride, 1], padding = \"SAME\")\n",
    "    output_layer_2 = tf.nn.bias_add(output_layer_2, bs[\"b2\"])\n",
    "    conv2 = tf.nn.relu(output_layer_2)\n",
    "    #max pooling (down-sampling)\n",
    "    output_layer_2 = maxpool2d(conv2)\n",
    "    \n",
    "    #fully connected layer\n",
    "    #reshape output_layer_2 to fit as i/p to fully connected layer\n",
    "    full_input = tf.reshape(output_layer_2, [-1, ws[\"w_full\"].get_shape().as_list()[0]])\n",
    "    \n",
    "    full_layer_op = tf.add(tf.matmul(full_input,ws[\"w_full\"]), bs[\"b_full\"])\n",
    "    output_layer = tf.nn.relu(full_layer_op)\n",
    "    \n",
    "    #incorporate dropouts\n",
    "    out_dropout = tf.nn.dropout(output_layer, dropouts)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_dropout, ws[\"w_\"]), bs[\"b_\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Model call\n",
    "pred = conv_net(x, W, b, keep_prob)\n",
    "\n",
    "#Now, every time this model is rerun to train, it will work towards reducing the loss and error\n",
    "#Loss reduction will be based on cross entropy 1/(1+e**-x)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= pred, labels= y))\n",
    "\n",
    "# AdamOptimizer training\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#Evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 loss: 12.8539 accuracy: 0.12\n",
      "Epoch: 06 loss: 2.99089 accuracy: 0.02\n",
      "Epoch: 11 loss: 2.77044 accuracy: 0.0\n",
      "Epoch: 16 loss: 2.46856 accuracy: 0.1\n",
      "Epoch: 21 loss: 2.35078 accuracy: 0.16\n",
      "Epoch: 26 loss: 2.31135 accuracy: 0.12\n",
      "Epoch: 31 loss: 2.30445 accuracy: 0.1\n",
      "Epoch: 36 loss: 2.28548 accuracy: 0.2\n",
      "Epoch: 41 loss: 2.30233 accuracy: 0.06\n",
      "Epoch: 46 loss: 2.30046 accuracy: 0.12\n",
      "Epoch: 51 loss: 2.29653 accuracy: 0.16\n",
      "Epoch: 56 loss: 2.30414 accuracy: 0.08\n",
      "Epoch: 61 loss: 2.30178 accuracy: 0.14\n",
      "Epoch: 66 loss: 2.29708 accuracy: 0.16\n",
      "Epoch: 71 loss: 2.31979 accuracy: 0.02\n",
      "Epoch: 76 loss: 2.29587 accuracy: 0.16\n",
      "Epoch: 81 loss: 2.29762 accuracy: 0.12\n",
      "Epoch: 86 loss: 2.30377 accuracy: 0.08\n",
      "Epoch: 91 loss: 2.29859 accuracy: 0.08\n",
      "Epoch: 96 loss: 2.32748 accuracy: 0.04\n",
      "Epoch: 101 loss: 2.30876 accuracy: 0.06\n",
      "Epoch: 106 loss: 2.31187 accuracy: 0.1\n",
      "Epoch: 111 loss: 2.29833 accuracy: 0.12\n",
      "Epoch: 116 loss: 2.29593 accuracy: 0.14\n",
      "Epoch: 121 loss: 2.3028 accuracy: 0.12\n",
      "Epoch: 126 loss: 2.31549 accuracy: 0.06\n",
      "Epoch: 131 loss: 2.30716 accuracy: 0.12\n",
      "Epoch: 136 loss: 2.32101 accuracy: 0.02\n",
      "Epoch: 141 loss: 2.29723 accuracy: 0.1\n",
      "Epoch: 146 loss: 2.30679 accuracy: 0.02\n",
      "Epoch: 151 loss: 2.29763 accuracy: 0.16\n",
      "Epoch: 156 loss: 2.29764 accuracy: 0.06\n",
      "Epoch: 161 loss: 2.29372 accuracy: 0.1\n",
      "Epoch: 166 loss: 2.30939 accuracy: 0.14\n",
      "Epoch: 171 loss: 2.31681 accuracy: 0.1\n",
      "Epoch: 176 loss: 2.28304 accuracy: 0.16\n",
      "Epoch: 181 loss: 2.299 accuracy: 0.08\n",
      "Epoch: 186 loss: 2.3085 accuracy: 0.06\n",
      "Epoch: 191 loss: 2.30633 accuracy: 0.06\n",
      "Epoch: 196 loss: 2.27667 accuracy: 0.2\n",
      "Epoch: 201 loss: 2.28609 accuracy: 0.18\n",
      "Epoch: 206 loss: 2.30431 accuracy: 0.06\n",
      "Epoch: 211 loss: 2.30613 accuracy: 0.1\n",
      "Epoch: 216 loss: 2.29705 accuracy: 0.08\n",
      "Epoch: 221 loss: 2.29584 accuracy: 0.12\n",
      "Epoch: 226 loss: 2.3036 accuracy: 0.12\n",
      "Epoch: 231 loss: 2.30129 accuracy: 0.1\n",
      "Epoch: 236 loss: 2.30134 accuracy: 0.14\n",
      "Epoch: 241 loss: 2.30902 accuracy: 0.06\n",
      "Epoch: 246 loss: 2.29839 accuracy: 0.14\n",
      "Epoch: 251 loss: 2.29748 accuracy: 0.1\n",
      "Epoch: 256 loss: 2.29732 accuracy: 0.08\n",
      "Epoch: 261 loss: 2.31087 accuracy: 0.08\n",
      "Epoch: 266 loss: 2.29752 accuracy: 0.12\n",
      "Epoch: 271 loss: 2.29423 accuracy: 0.16\n",
      "Epoch: 276 loss: 2.31005 accuracy: 0.1\n",
      "Epoch: 281 loss: 2.2897 accuracy: 0.16\n",
      "Epoch: 286 loss: 2.29532 accuracy: 0.12\n",
      "Epoch: 291 loss: 2.28685 accuracy: 0.18\n",
      "Epoch: 296 loss: 2.29208 accuracy: 0.14\n",
      "Epoch: 301 loss: 2.29681 accuracy: 0.16\n",
      "Epoch: 306 loss: 2.27914 accuracy: 0.26\n",
      "Epoch: 311 loss: 2.30102 accuracy: 0.16\n",
      "Epoch: 316 loss: 2.30134 accuracy: 0.16\n",
      "Epoch: 321 loss: 2.28168 accuracy: 0.18\n",
      "Epoch: 326 loss: 2.29558 accuracy: 0.08\n",
      "Epoch: 331 loss: 2.30539 accuracy: 0.08\n",
      "Epoch: 336 loss: 2.29789 accuracy: 0.16\n",
      "Epoch: 341 loss: 2.30177 accuracy: 0.1\n",
      "Epoch: 346 loss: 2.28873 accuracy: 0.12\n",
      "Epoch: 351 loss: 2.30497 accuracy: 0.08\n",
      "Epoch: 356 loss: 2.3069 accuracy: 0.06\n",
      "Epoch: 361 loss: 2.31294 accuracy: 0.06\n",
      "Epoch: 366 loss: 2.29504 accuracy: 0.12\n",
      "Epoch: 371 loss: 2.28945 accuracy: 0.22\n",
      "Epoch: 376 loss: 2.30289 accuracy: 0.14\n",
      "Epoch: 381 loss: 2.29034 accuracy: 0.2\n",
      "Epoch: 386 loss: 2.30266 accuracy: 0.08\n",
      "Epoch: 391 loss: 2.3016 accuracy: 0.08\n",
      "Epoch: 396 loss: 2.30247 accuracy: 0.12\n",
      "Epoch: 401 loss: 2.29959 accuracy: 0.08\n",
      "Epoch: 406 loss: 2.29527 accuracy: 0.12\n",
      "Epoch: 411 loss: 2.30921 accuracy: 0.1\n",
      "Epoch: 416 loss: 2.29102 accuracy: 0.14\n",
      "Epoch: 421 loss: 2.30761 accuracy: 0.06\n",
      "Epoch: 426 loss: 2.29772 accuracy: 0.16\n",
      "Epoch: 431 loss: 2.30602 accuracy: 0.1\n",
      "Epoch: 436 loss: 2.30571 accuracy: 0.1\n",
      "Epoch: 441 loss: 2.30783 accuracy: 0.08\n",
      "Epoch: 446 loss: 2.30267 accuracy: 0.1\n",
      "Epoch: 451 loss: 2.29653 accuracy: 0.2\n",
      "Epoch: 456 loss: 2.29462 accuracy: 0.2\n",
      "Epoch: 461 loss: 2.30658 accuracy: 0.08\n",
      "Epoch: 466 loss: 2.3077 accuracy: 0.06\n",
      "Epoch: 471 loss: 2.29482 accuracy: 0.12\n",
      "Epoch: 476 loss: 2.30333 accuracy: 0.06\n",
      "Epoch: 481 loss: 2.30252 accuracy: 0.12\n",
      "Epoch: 486 loss: 2.30248 accuracy: 0.06\n",
      "Epoch: 491 loss: 2.30102 accuracy: 0.16\n",
      "Epoch: 496 loss: 2.31157 accuracy: 0.06\n",
      "Epoch: 501 loss: 2.31448 accuracy: 0.06\n",
      "Epoch: 506 loss: 2.29977 accuracy: 0.08\n",
      "Epoch: 511 loss: 2.30244 accuracy: 0.1\n",
      "Epoch: 516 loss: 2.29715 accuracy: 0.08\n",
      "Epoch: 521 loss: 2.29875 accuracy: 0.1\n",
      "Epoch: 526 loss: 2.30023 accuracy: 0.14\n",
      "Epoch: 531 loss: 2.28355 accuracy: 0.22\n",
      "Epoch: 536 loss: 2.29303 accuracy: 0.16\n",
      "Epoch: 541 loss: 2.31432 accuracy: 0.08\n",
      "Epoch: 546 loss: 2.30091 accuracy: 0.1\n",
      "Epoch: 551 loss: 2.28493 accuracy: 0.18\n",
      "Epoch: 556 loss: 2.29396 accuracy: 0.12\n",
      "Epoch: 561 loss: 2.2917 accuracy: 0.18\n",
      "Epoch: 566 loss: 2.30134 accuracy: 0.12\n",
      "Epoch: 571 loss: 2.30513 accuracy: 0.1\n",
      "Epoch: 576 loss: 2.30143 accuracy: 0.12\n",
      "Epoch: 581 loss: 2.29369 accuracy: 0.16\n",
      "Epoch: 586 loss: 2.29864 accuracy: 0.1\n",
      "Epoch: 591 loss: 2.29258 accuracy: 0.16\n",
      "Epoch: 596 loss: 2.29264 accuracy: 0.12\n",
      "Epoch: 601 loss: 2.31208 accuracy: 0.08\n",
      "Epoch: 606 loss: 2.29633 accuracy: 0.16\n",
      "Epoch: 611 loss: 2.31088 accuracy: 0.14\n",
      "Epoch: 616 loss: 2.29755 accuracy: 0.12\n",
      "Epoch: 621 loss: 2.30715 accuracy: 0.1\n",
      "Epoch: 626 loss: 2.30803 accuracy: 0.08\n",
      "Epoch: 631 loss: 2.29695 accuracy: 0.14\n",
      "Epoch: 636 loss: 2.30184 accuracy: 0.06\n",
      "Epoch: 641 loss: 2.30746 accuracy: 0.06\n",
      "Epoch: 646 loss: 2.29217 accuracy: 0.2\n",
      "Epoch: 651 loss: 2.28874 accuracy: 0.12\n",
      "Epoch: 656 loss: 2.30752 accuracy: 0.16\n",
      "Epoch: 661 loss: 2.29842 accuracy: 0.16\n",
      "Epoch: 666 loss: 2.30227 accuracy: 0.1\n",
      "Epoch: 671 loss: 2.29855 accuracy: 0.16\n",
      "Epoch: 676 loss: 2.30162 accuracy: 0.08\n",
      "Epoch: 681 loss: 2.30147 accuracy: 0.08\n",
      "Epoch: 686 loss: 2.30329 accuracy: 0.08\n",
      "Epoch: 691 loss: 2.29785 accuracy: 0.16\n",
      "Epoch: 696 loss: 2.30105 accuracy: 0.1\n",
      "Epoch: 701 loss: 2.29227 accuracy: 0.18\n",
      "Epoch: 706 loss: 2.28856 accuracy: 0.14\n",
      "Epoch: 711 loss: 2.29751 accuracy: 0.14\n",
      "Epoch: 716 loss: 2.2971 accuracy: 0.14\n",
      "Epoch: 721 loss: 2.30233 accuracy: 0.08\n",
      "Epoch: 726 loss: 2.30586 accuracy: 0.1\n",
      "Epoch: 731 loss: 2.29883 accuracy: 0.18\n",
      "Epoch: 736 loss: 2.30816 accuracy: 0.04\n",
      "Epoch: 741 loss: 2.30812 accuracy: 0.12\n",
      "Epoch: 746 loss: 2.30185 accuracy: 0.08\n",
      "Epoch: 751 loss: 2.28834 accuracy: 0.18\n",
      "Epoch: 756 loss: 2.28601 accuracy: 0.22\n",
      "Epoch: 761 loss: 2.2944 accuracy: 0.18\n",
      "Epoch: 766 loss: 2.30135 accuracy: 0.14\n",
      "Epoch: 771 loss: 2.29136 accuracy: 0.2\n",
      "Epoch: 776 loss: 2.30418 accuracy: 0.12\n",
      "Epoch: 781 loss: 2.29809 accuracy: 0.14\n",
      "Epoch: 786 loss: 2.30047 accuracy: 0.12\n",
      "Epoch: 791 loss: 2.28415 accuracy: 0.22\n",
      "Epoch: 796 loss: 2.29679 accuracy: 0.18\n",
      "Epoch: 801 loss: 2.30323 accuracy: 0.14\n",
      "Epoch: 806 loss: 2.30542 accuracy: 0.14\n",
      "Epoch: 811 loss: 2.29847 accuracy: 0.1\n",
      "Epoch: 816 loss: 2.30479 accuracy: 0.12\n",
      "Epoch: 821 loss: 2.30535 accuracy: 0.1\n",
      "Epoch: 826 loss: 2.28723 accuracy: 0.2\n",
      "Epoch: 831 loss: 2.30095 accuracy: 0.12\n",
      "Epoch: 836 loss: 2.31049 accuracy: 0.12\n",
      "Epoch: 841 loss: 2.29325 accuracy: 0.1\n",
      "Epoch: 846 loss: 2.32331 accuracy: 0.02\n",
      "Epoch: 851 loss: 2.31335 accuracy: 0.06\n",
      "Epoch: 856 loss: 2.30566 accuracy: 0.1\n",
      "Epoch: 861 loss: 2.30343 accuracy: 0.1\n",
      "Epoch: 866 loss: 2.29846 accuracy: 0.12\n",
      "Epoch: 871 loss: 2.32163 accuracy: 0.06\n",
      "Epoch: 876 loss: 2.29614 accuracy: 0.1\n",
      "Epoch: 881 loss: 2.29444 accuracy: 0.1\n",
      "Epoch: 886 loss: 2.30648 accuracy: 0.08\n",
      "Epoch: 891 loss: 2.29415 accuracy: 0.18\n",
      "Epoch: 896 loss: 2.30623 accuracy: 0.06\n"
     ]
    }
   ],
   "source": [
    "##Initialize all variables and launch session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Training steps\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        #Training will be in batches now\n",
    "        for i in range(total_batch):\n",
    "            #pick up one batch at a time\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict = {x: batch_xs,\n",
    "                                             y: batch_ys,\n",
    "                                             keep_prob: dropout_percentage})\n",
    "            losses, accuracies = sess.run([loss, accuracy], feed_dict = {x: batch_xs,\n",
    "                                                                     y: batch_ys,\n",
    "                                                                     keep_prob: 1.})\n",
    "        if epoch%5 == 0:\n",
    "            print \"Epoch:\", \"%02d\" % (epoch+1), \"loss:\", losses, \"accuracy:\", accuracies\n",
    "            \n",
    "    print \"Training finished\"  \n",
    "    \n",
    "    # Test model\n",
    "    print \"Testing Accuracy:\", sess.run(accuracy, feed_dict= {x: mnist.test.images[:256], \n",
    "                                                              y: mnist.test.labels[:256],\n",
    "                                                              keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 40 hours this is the accuracy achieved. It can definitely be improved with a more finely tuned model and a better CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
