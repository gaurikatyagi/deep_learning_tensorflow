{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior.\n",
    "\n",
    "Recurrent networks are distinguished from feedforward networks by that feedback loop, ingesting their own outputs moment after moment as input. It is often said that recurrent networks have memory. Adding memory to neural networks has a purpose: There is information in the sequence itself, and recurrent nets use it to perform tasks that feedforward networks canâ€™t.\n",
    "\n",
    "Here's a great article: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setting up tensforflow parameters\n",
    "learning_rate =  0.001\n",
    "training_iterations = 100000\n",
    "batch_size = 128\n",
    "\n",
    "#Network Paramaters\n",
    "n_hidden = 128 #number of nodes in hidden layer\n",
    "n_steps = 28 #number of times to iterate over self\n",
    "n_inputs = 28 #MNIST data 28pixels for each image\n",
    "n_classes = 10 #Output can be 1 of the 10 numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#TF graph inputs\n",
    "\n",
    "#mnist images are of shape 28*28 = 784\n",
    "#We do not know the number of images/ they will be different for train and test thus None, steps, number inputs\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_inputs])\n",
    "\n",
    "#y, i.e. the result can be any number from 0 to 9 in onehot encoded format\n",
    "y = tf.placeholder(\"float\", [None, n_classes]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Defining weights and bias\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "b = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(xs, w, b):\n",
    "    \"\"\"\n",
    "    The LSTM (Long/short term memory RNN) model I plan on building requires all data\n",
    "    to be passed as parameters. Shape of the data needs to a tensor of the shape of \n",
    "    n_steps*batch_size, number of inputs\n",
    "    \"\"\"\n",
    "    x = tf.transpose(xs, [1, 0, 2]) #makes the oth index 1, 1th index o and 2nd index as is\n",
    "    x = tf.reshape(x, [-1, n_inputs]) #columns are the number of images and automaticlly \n",
    "    #decide the number of rows\n",
    "    \n",
    "    ##Splitting images in bulk of number of steps \n",
    "    ## Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(x, n_steps, 0)\n",
    "    \n",
    "    lstm_obj = rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "    outputs, states = rnn.static_rnn(lstm_obj, x, dtype = tf.float32)\n",
    "    \n",
    "    #Liear activation on last loop for output\n",
    "    return tf.add(tf.matmul(outputs[-1], w), b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = rnn_model(x, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "#Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#initilaization\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1280 loss:  1.91178 Accuracy:  0.367188\n",
      "Iteration:  2560 loss:  1.70376 Accuracy:  0.421875\n",
      "Iteration:  3840 loss:  1.3589 Accuracy:  0.5\n",
      "Iteration:  5120 loss:  1.17619 Accuracy:  0.59375\n",
      "Iteration:  6400 loss:  0.887656 Accuracy:  0.71875\n",
      "Iteration:  7680 loss:  1.30655 Accuracy:  0.585938\n",
      "Iteration:  8960 loss:  0.983267 Accuracy:  0.648438\n",
      "Iteration:  10240 loss:  0.750213 Accuracy:  0.75\n",
      "Iteration:  11520 loss:  0.465928 Accuracy:  0.890625\n",
      "Iteration:  12800 loss:  0.737447 Accuracy:  0.726562\n",
      "Iteration:  14080 loss:  0.684177 Accuracy:  0.765625\n",
      "Iteration:  15360 loss:  0.382037 Accuracy:  0.90625\n",
      "Iteration:  16640 loss:  0.451465 Accuracy:  0.898438\n",
      "Iteration:  17920 loss:  0.312327 Accuracy:  0.882812\n",
      "Iteration:  19200 loss:  0.343009 Accuracy:  0.835938\n",
      "Iteration:  20480 loss:  0.176603 Accuracy:  0.960938\n",
      "Iteration:  21760 loss:  0.486304 Accuracy:  0.84375\n",
      "Iteration:  23040 loss:  0.237851 Accuracy:  0.921875\n",
      "Iteration:  24320 loss:  0.385988 Accuracy:  0.859375\n",
      "Iteration:  25600 loss:  0.403797 Accuracy:  0.859375\n",
      "Iteration:  26880 loss:  0.19 Accuracy:  0.953125\n",
      "Iteration:  28160 loss:  0.267487 Accuracy:  0.898438\n",
      "Iteration:  29440 loss:  0.331068 Accuracy:  0.898438\n",
      "Iteration:  30720 loss:  0.362627 Accuracy:  0.859375\n",
      "Iteration:  32000 loss:  0.236217 Accuracy:  0.890625\n",
      "Iteration:  33280 loss:  0.289117 Accuracy:  0.898438\n",
      "Iteration:  34560 loss:  0.212097 Accuracy:  0.9375\n",
      "Iteration:  35840 loss:  0.244577 Accuracy:  0.929688\n",
      "Iteration:  37120 loss:  0.275812 Accuracy:  0.929688\n",
      "Iteration:  38400 loss:  0.163731 Accuracy:  0.9375\n",
      "Iteration:  39680 loss:  0.129395 Accuracy:  0.976562\n",
      "Iteration:  40960 loss:  0.332332 Accuracy:  0.914062\n",
      "Iteration:  42240 loss:  0.104568 Accuracy:  0.96875\n",
      "Iteration:  43520 loss:  0.136902 Accuracy:  0.960938\n",
      "Iteration:  44800 loss:  0.223007 Accuracy:  0.914062\n",
      "Iteration:  46080 loss:  0.10279 Accuracy:  0.976562\n",
      "Iteration:  47360 loss:  0.239073 Accuracy:  0.9375\n",
      "Iteration:  48640 loss:  0.238169 Accuracy:  0.945312\n",
      "Iteration:  49920 loss:  0.245622 Accuracy:  0.890625\n",
      "Iteration:  51200 loss:  0.110559 Accuracy:  0.960938\n",
      "Iteration:  52480 loss:  0.199503 Accuracy:  0.929688\n",
      "Iteration:  53760 loss:  0.0595682 Accuracy:  0.976562\n",
      "Iteration:  55040 loss:  0.220718 Accuracy:  0.921875\n",
      "Iteration:  56320 loss:  0.22573 Accuracy:  0.914062\n",
      "Iteration:  57600 loss:  0.196659 Accuracy:  0.945312\n",
      "Iteration:  58880 loss:  0.131679 Accuracy:  0.945312\n",
      "Iteration:  60160 loss:  0.0859311 Accuracy:  0.96875\n",
      "Iteration:  61440 loss:  0.115966 Accuracy:  0.960938\n",
      "Iteration:  62720 loss:  0.206465 Accuracy:  0.921875\n",
      "Iteration:  64000 loss:  0.0982077 Accuracy:  0.96875\n",
      "Iteration:  65280 loss:  0.201868 Accuracy:  0.953125\n",
      "Iteration:  66560 loss:  0.152134 Accuracy:  0.953125\n",
      "Iteration:  67840 loss:  0.17531 Accuracy:  0.953125\n",
      "Iteration:  69120 loss:  0.13529 Accuracy:  0.953125\n",
      "Iteration:  70400 loss:  0.180354 Accuracy:  0.9375\n",
      "Iteration:  71680 loss:  0.122438 Accuracy:  0.960938\n",
      "Iteration:  72960 loss:  0.111969 Accuracy:  0.960938\n",
      "Iteration:  74240 loss:  0.0884287 Accuracy:  0.960938\n",
      "Iteration:  75520 loss:  0.116651 Accuracy:  0.96875\n",
      "Iteration:  76800 loss:  0.11179 Accuracy:  0.96875\n",
      "Iteration:  78080 loss:  0.145798 Accuracy:  0.984375\n",
      "Iteration:  79360 loss:  0.111558 Accuracy:  0.976562\n",
      "Iteration:  80640 loss:  0.074169 Accuracy:  0.96875\n",
      "Iteration:  81920 loss:  0.100193 Accuracy:  0.960938\n",
      "Iteration:  83200 loss:  0.105822 Accuracy:  0.96875\n",
      "Iteration:  84480 loss:  0.0689969 Accuracy:  0.976562\n",
      "Iteration:  85760 loss:  0.173641 Accuracy:  0.953125\n",
      "Iteration:  87040 loss:  0.102191 Accuracy:  0.96875\n",
      "Iteration:  88320 loss:  0.0591841 Accuracy:  0.984375\n",
      "Iteration:  89600 loss:  0.0558739 Accuracy:  0.976562\n",
      "Iteration:  90880 loss:  0.146776 Accuracy:  0.953125\n",
      "Iteration:  92160 loss:  0.0770481 Accuracy:  0.976562\n",
      "Iteration:  93440 loss:  0.107119 Accuracy:  0.960938\n",
      "Iteration:  94720 loss:  0.0556026 Accuracy:  0.984375\n",
      "Iteration:  96000 loss:  0.0997193 Accuracy:  0.945312\n",
      "Iteration:  97280 loss:  0.0531081 Accuracy:  0.984375\n",
      "Iteration:  98560 loss:  0.0600604 Accuracy:  0.984375\n",
      "Iteration:  99840 loss:  0.140284 Accuracy:  0.960938\n",
      "Done Training\n",
      "Test Accuracy: 0.980469\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    \n",
    "    #Train till maximum iterations\n",
    "    while step*batch_size < training_iterations:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        #Reshape data to get 28 sequences of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_inputs))\n",
    "        sess.run(optimizer, feed_dict = {x:batch_x, y: batch_y})\n",
    "        \n",
    "        if step%10 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict = {x: batch_x, y:batch_y})\n",
    "            loss = sess.run(cost, feed_dict = {x:batch_x, y:batch_y})\n",
    "            print \"Iteration: \", str(step*batch_size), \"loss: \", loss, \"Accuracy: \", acc\n",
    "    \n",
    "        step += 1\n",
    "    \n",
    "    print \"Done Training\"\n",
    "    \n",
    "    test_data = mnist.test.images[:256].reshape((-1, n_steps, n_inputs))\n",
    "    test_label = mnist.test.labels[:256]\n",
    "    print \"Test Accuracy:\", sess.run(accuracy, feed_dict = {x: test_data, y: test_label})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
