{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, logistic regression, or logit regression, or logit model is a regression model where the dependent variable (DV) is categorical.\n",
    "\n",
    "Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x1111dd790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0] #tensforflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x111220650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0] #tensforflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up tensforflow parameters\n",
    "learning_rate =  0.1 #0.03 and 0.2 gave cost of 2.30258369446 always\n",
    "training_epochs = 100\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TF graph inputs\n",
    "\n",
    "#mnist images are of shape 28*28 = 784\n",
    "#We do not know the number of images/ they will be different for train and test thus None, 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "#y, i.e. the result can be any number from 0 to 9 in onehot encoded format\n",
    "y = tf.placeholder(tf.float32, [None, 10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining weights and bias\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#Model construction\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) #Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, every time this model is rerun to train, it will work towards reducing the loss and error\n",
    "#Loss reduction will be based on cross entropy 1/(1+e**-x)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices = 1))\n",
    "\n",
    "#Gradient Descent training\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 2.30258369446\n",
      "Epoch: 0006 cost= 2.30258369446\n",
      "Epoch: 0011 cost= 2.30258369446\n",
      "Epoch: 0016 cost= 2.30258369446\n",
      "Epoch: 0021 cost= 2.30258369446\n",
      "Epoch: 0026 cost= 2.30258369446\n",
      "Epoch: 0031 cost= 2.30258369446\n",
      "Epoch: 0036 cost= 2.30258369446\n",
      "Epoch: 0041 cost= 2.30258369446\n",
      "Epoch: 0046 cost= 2.30258369446\n",
      "Epoch: 0051 cost= 2.30258369446\n",
      "Epoch: 0056 cost= 2.30258369446\n",
      "Epoch: 0061 cost= 2.30258369446\n",
      "Epoch: 0066 cost= 2.30258369446\n",
      "Epoch: 0071 cost= 2.30258369446\n",
      "Epoch: 0076 cost= 2.30258369446\n",
      "Epoch: 0081 cost= 2.30258369446\n",
      "Epoch: 0086 cost= 2.30258369446\n",
      "Epoch: 0091 cost= 2.30258369446\n",
      "Epoch: 0096 cost= 2.30258369446\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "##Initialize all variables and launch session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Training steps\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        #Training will be in batches now\n",
    "        for i in range(total_batch):\n",
    "            #pick up one batch at a time\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            cost_ = sess.run(cost, feed_dict = {x: batch_xs,\n",
    "                                                  y: batch_ys})\n",
    "            \n",
    "            #computing intermediary loss\n",
    "            avg_cost += cost_/total_batch\n",
    "        \n",
    "        if epoch%5 ==0:\n",
    "            print \"Epoch:\", \"%04d\" % (epoch+1), \"cost=\", avg_cost\n",
    "            \n",
    "    print \"Training finished\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
