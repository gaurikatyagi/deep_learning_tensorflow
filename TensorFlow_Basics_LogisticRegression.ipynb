{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, logistic regression, or logit regression, or logit model is a regression model where the dependent variable (DV) is categorical.\n",
    "\n",
    "Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x1138656d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0] #tensforflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x113865a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0] #tensforflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up tensforflow parameters\n",
    "learning_rate =  0.03 #0.03 and 0.02 gave cost of 2.30258369446 always\n",
    "training_epochs = 25\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TF graph inputs\n",
    "\n",
    "#mnist images are of shape 28*28 = 784\n",
    "#We do not know the number of images/ they will be different for train and test thus None, 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "#y, i.e. the result can be any number from 0 to 9 in onehot encoded format\n",
    "y = tf.placeholder(tf.float32, [None, 10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining weights and bias\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#Model construction\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) #Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, every time this model is rerun to train, it will work towards reducing the loss and error\n",
    "#Loss reduction will be based on cross entropy 1/(1+e**-x)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices = 1))\n",
    "\n",
    "#Gradient Descent training\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 Cost: 2.30258536339\n",
      "Epoch: 06 Cost: 2.30258536339\n",
      "Epoch: 11 Cost: 2.30258536339\n",
      "Epoch: 16 Cost: 2.30258536339\n",
      "Epoch: 21 Cost: 2.30258536339\n",
      "Training finished\n",
      "Accuracy: 0.084\n"
     ]
    }
   ],
   "source": [
    "##Initialize all variables and launch session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Training steps\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        #Training will be in batches now\n",
    "        for i in range(total_batch):\n",
    "            #pick up one batch at a time\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            cost_ = sess.run(cost, feed_dict = {x: batch_xs,\n",
    "                                                  y: batch_ys})\n",
    "            \n",
    "            #computing intermediary loss\n",
    "            avg_cost += cost_ / total_batch\n",
    "        \n",
    "        if epoch%5 ==0:\n",
    "            print \"Epoch:\", \"%02d\" % (epoch+1), \"Cost:\", avg_cost\n",
    "            \n",
    "    print \"Training finished\"  \n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:1500], y: mnist.test.labels[:1500]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single layer model performs poorly. We will see further how the accuracy of models can be improved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
